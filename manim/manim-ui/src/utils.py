import re
import anthropic
import openai

PRE_PROMPT_APPEND = """Write Manim scripts for animations in Python. Generate code, not text. Never explain code. Never add functions. Never add comments. Never infinte loops. Never use other library than Manim/math. Only complete the code block. Use variables with length of maximum 2-3 characters.
```
from manim import *
from math import *

class GenScene(Scene):
    def construct(self):
        # Write here
```"""

# Define a function to query GPT-4
def query_gpt(client, input_text, history=None):
  history[-1]['content'] = PRE_PROMPT_APPEND + '  ' +  history[-1]['content']
  stream = client.chat.completions.create(
    model="text-davinci-003",
    messages=[
      {"role": m['role'], "content": m['content']}
      for m in history
    ],
  )
  yield stream

# Define a function to query Claude-3
def query_claude(client, input_text, history=None):
  print('QUERYING CLAUDE')
  history[-1]['content'] = PRE_PROMPT_APPEND + '  ' +  history[-1]['content']
  with client.messages.stream(
      model="claude-3-sonnet-20240229",
      max_tokens=2048,
      messages=[
          {"role": m['role'], "content": m['content']} for m in history
      ]
  ) as stream: 
    for text in stream.text_stream:  
      yield text 

def query_llm():
  new_user_input_ids = tokenizer.encode(tokenizer.eos_token + input_text,
                                        return_tensors='pt')

  bot_input_ids = torch.cat([history,
                              new_user_input_ids],
                              dim=-1) if history is not None else new_user_input_ids

  # generated a response while limiting the total chat history to 1000 tokens,
  chat_history_ids = model.generate(bot_input_ids,
                                    max_length=generate_size,
                                    pad_token_id=tokenizer.eos_token_id)

  return tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0],
                          skip_special_tokens=True), chat_history_ids

def wrap_prompt(prompt: str) -> str:
  """
    Wraps the prompt in the LLM instructions
  """
  return f"Animation Request: {prompt}"

def extract_code(text: str) -> str:
  """
    Extracts the code from the text generated by LLM from the ``` ``` blocks
  """
  pattern = re.compile(r"```(.*?)```", re.DOTALL)
  match = pattern.search(text)
  if match:
    return match.group(1).strip()
  else:
    return text

def extract_construct_code(code_str: str) -> str:
  """
    Extracts the code from the construct method
  """
  print('IN EXTRACT CODE!')
  pattern = r"def construct\(self\):([\s\S]*)"
  match = re.search(pattern, code_str)
  if match:
    return match.group(1)
  else:
    return ""


def create_file_content(code_response: str) -> str:
  """
    Creates the content of the file to be written
  """
  return f"""# Manim code generated from LLM
# Command to generate animation: manim GenScene.py GenScene --format=mp4 --media_dir .

from manim import *
from math import *

class GenScene(Scene):
    def construct(self):
{code_response}"""
